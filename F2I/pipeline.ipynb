{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top matches:\n",
      "                 company_name                               investor_type  \\\n",
      "97                DIVEdigital                             Venture Capital   \n",
      "144                     TRIVE                                    Micro VC   \n",
      "148                  IncuVest                Angel Group, Venture Capital   \n",
      "12            Promus Ventures                                    Micro VC   \n",
      "43   Boeing HorizonX Ventures  Corporate Venture Capital, Venture Capital   \n",
      "\n",
      "                                            industries  similarity_score  \n",
      "97   Artificial Intelligence, Machine Learning, Man...          1.000000  \n",
      "144  Analytics, Artificial Intelligence, Business I...          0.593795  \n",
      "148  Advanced Materials, Artificial Intelligence, A...          0.474880  \n",
      "12   Aerospace, AgTech, Artificial Intelligence, Fi...          0.418227  \n",
      "43   Advanced Materials, Artificial Intelligence, C...          0.399897  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/ipykernel_9082/575262405.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  investors_df['processed_description'] = investors_df['description'].apply(preprocess_text)\n",
      "/var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/ipykernel_9082/575262405.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  investors_df['combined_text'] = investors_df['processed_description'] + ' ' + investors_df['industries'].fillna('')\n",
      "/var/folders/57/dmb6w3ys4376hkdxj2pvws380000gn/T/ipykernel_9082/575262405.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_investors['similarity_score'] = similarity_scores\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    return str(text).lower().strip()\n",
    "\n",
    "def calculate_similarity_scores(investors_df, founder_data):\n",
    "    # Preprocess descriptions\n",
    "    investors_df['processed_description'] = investors_df['description'].apply(preprocess_text)\n",
    "    founder_desc = preprocess_text(founder_data['description'])\n",
    "    \n",
    "    # Combine industries and description for better matching\n",
    "    investors_df['combined_text'] = investors_df['processed_description'] + ' ' + investors_df['industries'].fillna('')\n",
    "    \n",
    "    # Create document list\n",
    "    documents = investors_df['combined_text'].tolist()\n",
    "    documents.append(founder_desc)\n",
    "    \n",
    "    # TF-IDF Vectorization with specific parameters\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        stop_words='english',\n",
    "        ngram_range=(1, 2),  # Include bigrams\n",
    "        min_df=1,            # Include all terms\n",
    "        max_df=0.9          # Exclude terms that appear in more than 90% of documents\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "        \n",
    "        # Calculate cosine similarity\n",
    "        cosine_similarities = cosine_similarity(tfidf_matrix[-1:], tfidf_matrix[:-1])[0]\n",
    "        \n",
    "        # Normalize scores to 0-1 range\n",
    "        normalized_scores = (cosine_similarities - cosine_similarities.min()) / \\\n",
    "                          (cosine_similarities.max() - cosine_similarities.min() + 1e-10)\n",
    "        \n",
    "        return normalized_scores\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in similarity calculation: {e}\")\n",
    "        return np.zeros(len(investors_df))\n",
    "\n",
    "# Load and process data\n",
    "investor_file_path = '/Users/sasanksasi/Downloads/project/VertexAi/dataset.csv'\n",
    "investors_df = pd.read_csv(investor_file_path)\n",
    "\n",
    "founder_data = {\n",
    "    'name': 'John Doe',\n",
    "    'description': 'A passionate entrepreneur in the field of artificial intelligence and machine learning.',\n",
    "    'industry': 'Artificial Intelligence'\n",
    "}\n",
    "\n",
    "# Filter relevant investors\n",
    "filtered_investors = investors_df[\n",
    "    investors_df['industries'].str.contains(founder_data['industry'], case=False, na=False)\n",
    "]\n",
    "\n",
    "# Calculate similarity scores\n",
    "similarity_scores = calculate_similarity_scores(filtered_investors, founder_data)\n",
    "filtered_investors['similarity_score'] = similarity_scores\n",
    "\n",
    "# Sort and display results\n",
    "sorted_investors = filtered_investors.sort_values(by='similarity_score', ascending=False)\n",
    "\n",
    "# Display top matches with scores\n",
    "print(\"\\nTop matches:\")\n",
    "print(sorted_investors[['company_name', 'investor_type', 'industries', 'similarity_score']].head())\n",
    "\n",
    "# Save results\n",
    "new_file_path = '/Users/sasanksasi/Downloads/project/VertexAi/Phase1_dataset.csv'\n",
    "sorted_investors.to_csv(new_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 12%|█▎        | 1/8 [00:01<00:11,  1.61s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 25%|██▌       | 2/8 [00:03<00:09,  1.57s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 38%|███▊      | 3/8 [00:04<00:07,  1.58s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 50%|█████     | 4/8 [00:06<00:06,  1.57s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 62%|██████▎   | 5/8 [00:07<00:04,  1.58s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 75%|███████▌  | 6/8 [00:09<00:03,  1.64s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 88%|████████▊ | 7/8 [00:11<00:01,  1.64s/it]INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 8/8 [00:13<00:00,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Investor Matches:\n",
      "            company_name                 investor_type  groq_score  \\\n",
      "1                  TRIVE                      Micro VC        85.0   \n",
      "2               IncuVest  Angel Group, Venture Capital        85.0   \n",
      "3        Promus Ventures                      Micro VC        85.0   \n",
      "5          Acton Capital               Venture Capital        85.0   \n",
      "7  Govin Capital Pte Ltd               Venture Capital        85.0   \n",
      "\n",
      "   final_score                                        explanation  \n",
      "1    59.678138  TRIVE is a micro VC firm that focuses on inves...  \n",
      "2    59.642464  IncuVest is a Singapore-based early and growth...  \n",
      "3    59.625468  Promus Ventures is a strong match for the foun...  \n",
      "5    59.535985  Acton Capital has a strong focus on tech-enabl...  \n",
      "7    59.500000  Govin Capital Pte Ltd appears to be a highly c...  \n",
      "Index(['company_name', 'investor_type', 'location', 'industries', 'groq_score',\n",
      "       'explanation', 'similarity_score', 'final_score'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "groq_client = Groq(api_key=os.getenv('GROQ_API_KEY'))\n",
    "\n",
    "class InvestorAnalyzer:\n",
    "    def __init__(self, groq_client):\n",
    "        self.groq_client = groq_client\n",
    "        \n",
    "    def analyze_investor(self, founder_data, investor):\n",
    "        prompt = f\"\"\"\n",
    "        Analyze the compatibility between this founder and investor:\n",
    "\n",
    "        Founder:\n",
    "        {founder_data['description']}\n",
    "        Industry Focus: {founder_data['industry']}\n",
    "\n",
    "        Investor:\n",
    "        Company: {investor['company_name']}\n",
    "        Type: {investor['investor_type']}\n",
    "        Description: {investor['description']}\n",
    "        Industries: {investor['industries']}\n",
    "        Location: {investor['location']}\n",
    "\n",
    "        Provide a structured analysis with:\n",
    "        1. Score (0-100)\n",
    "        2. Brief explanation\n",
    "        \n",
    "        Format: <score>|<explanation>\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            completion = self.groq_client.chat.completions.create(\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                model=\"mixtral-8x7b-32768\",\n",
    "                temperature=0.3,\n",
    "                max_tokens=150\n",
    "            )\n",
    "            response = completion.choices[0].message.content.strip()\n",
    "            \n",
    "            # Parse response\n",
    "            score, explanation = response.split('|')\n",
    "            return float(score), explanation.strip()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing {investor['company_name']}: {str(e)}\")\n",
    "            return 0, \"Analysis failed\"\n",
    "\n",
    "    def process_investors(self, investors_df, founder_data):\n",
    "        results = []\n",
    "        \n",
    "        # Process each investor with progress bar\n",
    "        for _, investor in tqdm(investors_df.iterrows(), total=len(investors_df)):\n",
    "            score, explanation = self.analyze_investor(founder_data, investor)\n",
    "            \n",
    "            results.append({\n",
    "                'company_name': investor['company_name'],\n",
    "                'investor_type': investor['investor_type'],\n",
    "                'location': investor['location'],\n",
    "                'industries': investor['industries'],\n",
    "                'groq_score': score,\n",
    "                'explanation': explanation,\n",
    "                'similarity_score': investor['similarity_score']\n",
    "            })\n",
    "            \n",
    "            # Rate limiting\n",
    "            time.sleep(1)\n",
    "            \n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "def main():\n",
    "    # Load dataset\n",
    "    investors_df = pd.read_csv('/Users/sasanksasi/Downloads/project/VertexAi/Phase1_dataset.csv')\n",
    "    \n",
    "    # Sample founder data\n",
    "    founder_data = {\n",
    "        'name': 'John Doe',\n",
    "        'description': 'Building an AI-powered healthcare diagnostics platform using computer vision and machine learning.',\n",
    "        'industry': 'Healthcare AI'\n",
    "    }\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    analyzer = InvestorAnalyzer(groq_client)\n",
    "    \n",
    "    # Process investors\n",
    "    results_df = analyzer.process_investors(investors_df, founder_data)\n",
    "    \n",
    "    # Calculate final score (weighted combination)\n",
    "    results_df['final_score'] = (\n",
    "        results_df['similarity_score'] * 0.3 + \n",
    "        results_df['groq_score'] * 0.7\n",
    "    )\n",
    "    \n",
    "    # Sort and display results\n",
    "    final_results = results_df.sort_values('final_score', ascending=False)\n",
    "    \n",
    "    # Display top matches\n",
    "    print(\"\\nTop Investor Matches:\")\n",
    "    print(final_results[['company_name', 'investor_type', 'groq_score', 'final_score', 'explanation']].head())\n",
    "    print(final_results.columns)\n",
    "    \n",
    "    # Save results\n",
    "    final_results.to_csv('investor_matches.csv', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
